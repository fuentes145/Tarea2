{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL-oYKcKICDz"
      },
      "source": [
        "# 2. Finetuning YOLOv5: ``You-Only-Look-Once\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad 4\n",
        "Investigue sobre la arquitectura de los modelos YOLO y explique los siguientes conceptos (para cada\n",
        "caso use solo 5 lÃ­neas mÃ¡ximo):\n",
        "\n",
        "\n",
        "â€¢ Diferencia entre frameworks de detecciÃ³n de objetos de una y dos etapas (single-stage vs.\n",
        "two-stage object detection).\n",
        "\n",
        "\n",
        "â€¢ FunciÃ³n de pÃ©rdida Complete Intersection Over Union (CIoU) y su uso en la red YOLOv5.\n",
        "\n",
        "\n",
        "â€¢ FunciÃ³n de pÃ©rdida Binary Cross Entropy (BCE) y su uso en la red YOLOv5.\n",
        "\n",
        "â€¢ Â¿CÃ³mo se calcula la funciÃ³n de pÃ©rdida total en YOLOv5?"
      ],
      "metadata": {
        "id": "yG6_FdclFGxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1.â€¯Singleâ€‘stage vs. Twoâ€‘stage object detection\n",
        "- **Modelos de una etapa (singleâ€‘stage)**, como YOLO, *predicen directamente* bounding boxesâ€¯+â€¯clases en un **Ãºnico paso** sobre la imagen, obteniendo gran velocidad.\n",
        "- **Modelos de dos etapas (twoâ€‘stage)**, como Fasterâ€¯Râ€‘CNN, primero generan **regiones propuestas (RPN)** y luego **refinan y clasifican** cada propuesta.\n",
        "- El enfoque de una etapa sacrifica algo de exactitud por latencia bajÃ­sima; el de dos etapas logra mejor mAP pero con mayor coste computacional.\n",
        "- En tareas de *streaming* o tiempo real, la relaciÃ³n *precisiÃ³n/velocidad* de YOLO lo hace preferible.\n",
        "\n",
        "## 2.â€¯PÃ©rdida CompleteÂ IoU (CIoU)\n",
        "La mÃ©trica CIoU extiende la IoU clÃ¡sica penalizando tambiÃ©n la distancia entre centros y la discrepancia de aspecto:\n",
        "\n",
        "$$\n",
        "\\text{CIoU}(b, b^{gt}) = \\text{IoU}\n",
        "- \\frac{\\rho^2(\\mathbf{c}, \\mathbf{c^{gt}})}{c^2}\n",
        "- \\alpha v\n",
        "$$\n",
        "\n",
        "con $\\rho$ la distancia euclÃ­dea entre centros, $c$ la diagonal del cuadro mÃ­nimo que los contiene, $v$ la divergencia de relaciÃ³n anchoâ€‘alto y $\\alpha$ un tÃ©rmino de equilibrio.\n",
        "\n",
        "- CIoU es **diferenciable** y conduce a convergencia mÃ¡s estable que IoU o GIoU.\n",
        "- YOLOv5 optimiza la posiciÃ³n de los *boxes* usando $L_\\text{CIoU} = 1 - \\text{CIoU}$.\n",
        "\n",
        "## 3.â€¯PÃ©rdida BinaryÂ CrossÂ Entropy (BCE)\n",
        "Para un ejemplo con etiqueta binaria $y \\in \\{0,1\\}$ y probabilidad predicha $p$:\n",
        "\n",
        "$$\n",
        "\\text{BCE}(p, y) = -\\big(y \\log p + (1 - y) \\log(1 - p)\\big)\n",
        "$$\n",
        "\n",
        "- En YOLOv5 hay **dos instancias** de BCE:\n",
        "  1. **Objectness**: decide si existe objeto en cada celdaâ€‘ancla.\n",
        "  2. **ClasificaciÃ³n**: distribuye probabilidad entre las $N$ clases (BCE por clase, activaciÃ³n sigmoid).\n",
        "- BCE es adecuada para etiquetas escasas y balances asimÃ©tricos.\n",
        "\n",
        "## 4.â€¯FunciÃ³n de pÃ©rdida total en YOLOv5\n",
        "La red minimiza una suma ponderada de tres componentes:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_\\text{total}\n",
        "= \\lambda_{\\text{box}}\\,\\mathcal{L}_{\\text{CIoU}}\n",
        "+ \\lambda_{\\text{obj}}\\,\\mathcal{L}_{\\text{BCE,obj}}\n",
        "+ \\lambda_{\\text{cls}}\\,\\mathcal{L}_{\\text{BCE,cls}}\n",
        "$$\n",
        "\n",
        "- $\\mathcal{L}_{\\text{CIoU}}$ ajusta posiciÃ³n y tamaÃ±o de los *bounding boxes*.\n",
        "- $\\mathcal{L}_{\\text{BCE,obj}}$ refuerza la correcta predicciÃ³n de presencia de objeto.\n",
        "- $\\mathcal{L}_{\\text{BCE,cls}}$ impulsa la clasificaciÃ³n de la clase.\n",
        "- Los pesos $\\lambda$ se afinan empÃ­ricamente, tÃ­picamente $\\approx (0.05, 1.0, 0.5)$, para equilibrar localizaciÃ³n y reconocimiento.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "A1aJXwJCFVtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad 5\n",
        "Investigue sobre el output de la red YOLOv5 y cÃ³mo se traduce el tensor de salida a bounding boxes\n",
        "y detecciones de objetos. AdemÃ¡s, explique cÃ³mo, en general, se obtiene solamente una detecciÃ³n\n",
        "por objeto, y no varias para todas las regiones donde el objeto estÃ¡ presente. AdemÃ¡s, investigue el\n",
        "rol de la augmentaciÃ³n de datos en el entrenamiento de YOLOv5."
      ],
      "metadata": {
        "id": "Fp33Qw3LJMRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1.Â DecodificaciÃ³n del tensor de salida a *bounding boxes*\n",
        "YOLOv5 produce un tensor de forma `(B, A*(5+C), H, W)` donde:\n",
        "- *B* = batch, *A* = anclas por celda, *C* = nÃºmero de clases, *HÃ—W* = tamaÃ±o de la malla.\n",
        "- Para cada ancla la red predice $\\big(t_x,\\,t_y,\\,t_w,\\,t_h,\\,p_{obj},\\,p_{cls,1\\dots C}\\big)$.\n",
        "\n",
        "Las coordenadas se decodifican con\n",
        "$$\n",
        "\\begin{aligned}\n",
        " x &= \\frac{\\sigma(t_x)+c_x}{W},\\\\\n",
        " y &= \\frac{\\sigma(t_y)+c_y}{H},\\\\\n",
        " w &= \\frac{e^{t_w}\\,a_w}{\\text{img}_w},\\\\\n",
        " h &= \\frac{e^{t_h}\\,a_h}{\\text{img}_h},\n",
        "\\end{aligned}\n",
        "$$\n",
        "donde $(c_x,c_y)$ son las coordenadas de la celda, $(a_w,a_h)$ las dimensiones del ancla y $\\sigma$ la sigmoide. AsÃ­ se obtienen *bounding boxes* normalizados $(x,y,w,h)$.\n",
        "\n",
        "## 2.Â Una sola detecciÃ³n por objeto: *Nonâ€‘Max Suppression* (NMS)\n",
        "- DespuÃ©s de decodificar, cada *box* lleva una confianza $p = \\sigma(p_{obj})\\max_j p_{cls,j}$.\n",
        "- Se descartan boxes con $p$ bajo (threshold).\n",
        "- Sobre los restantes se aplica **NMS**: se mantienen los boxes con mayor confianza y se eliminan los que tengan IoU $>\\tau$ con alguno ya aceptado.\n",
        "- YOLOv5 usa variantes como *CIoUâ€‘NMS* o *Weighted NMS* segÃºn la versiÃ³n, pero el principio es idÃ©ntico: una sola predicciÃ³n por objeto.\n",
        "\n",
        "## 3.Â Rol del aumento de datos (*data augmentation*)\n",
        "El *augment* amplÃ­a la diversidad del set y mejora la generalizaciÃ³n:\n",
        "- **GeometrÃ­a**: escalado, recorte, volteo, rotaciones (Ãºtiles cuando la orientaciÃ³n del satÃ©lite varÃ­a).\n",
        "- **Color**: jitter HSV, blur, ruido.\n",
        "- **Mosaic & MixUp**: combinan cuatro imÃ¡genes o mezclan pares, exponiendo mÃºltiples objetos a cada contexto.\n",
        "- Beneficios principales: reduce *overfitting*, mejora robustez ante variaciones de iluminaciÃ³n/escala y estabiliza el entrenamiento cuando los datos son escasos.\n",
        "\n",
        "En YOLOv5 el mÃ³dulo `Albumentations` (o la implementaciÃ³n interna de Ultralytics) integra estos *transforms* antes de pasar las imÃ¡genes por la red.\n"
      ],
      "metadata": {
        "id": "ZxFgHXl5FJJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Actividad 6\n",
        "En el notebook, deberÃ¡n hacer fine-tuning para que una instancia de YOLOv5 pueda realizar seg-\n",
        "mentaciones de datos satelitales. Para esto, se encuentra implementado la carga del modelo YOLOv5\n",
        "\n",
        "con los parÃ¡metros congelados salvo la cabeza de detecciÃ³n. Se encuentra ademÃ¡s el cÃ³digo para\n",
        "cargar y preprocesar el set de datos. Se deben completar las siguientes funciones:"
      ],
      "metadata": {
        "id": "HZ7E6eC8Kiby"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLKMzG0M3fTr",
        "outputId": "12da42e0-c5dd-4a39-9449-3f3a6de90d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.1.63)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Requirement already satisfied: pillow-heif>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.22.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "# Para cargar un dataset desde Roboflow\n",
        "from roboflow import Roboflow\n",
        "my_key = \"hhJFVyqL27We1hzvzNAa\"\n",
        "rf = Roboflow(api_key=my_key)\n",
        "project = rf.workspace(\"cvproject-y6bf4\").project(\"vehicle-detection-gr77r\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywGGeJWGhCmU",
        "outputId": "12b3f887-a6d6-4f20-ac3f-adfde72ece90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.15.2)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: ultralytics>=8.2.34 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (8.3.128)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.14)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "--2025-05-07 02:39:24--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/381bd8a8-8910-4e9e-b0dd-2752951ef78c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250507%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250507T023924Z&X-Amz-Expires=300&X-Amz-Signature=45426fcbb86b5a4a93028a509e2374f5d207c8a452c9ed97d705ca937473986d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-07 02:39:24--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/381bd8a8-8910-4e9e-b0dd-2752951ef78c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250507%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250507T023924Z&X-Amz-Expires=300&X-Amz-Signature=45426fcbb86b5a4a93028a509e2374f5d207c8a452c9ed97d705ca937473986d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14808437 (14M) [application/octet-stream]\n",
            "Saving to: â€˜yolov5s.pt.2â€™\n",
            "\n",
            "yolov5s.pt.2        100%[===================>]  14.12M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-05-07 02:39:24 (108 MB/s) - â€˜yolov5s.pt.2â€™ saved [14808437/14808437]\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Instalar dependencias de YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n",
        "!pip install opencv-python\n",
        "!pip install torchinfo\n",
        "!wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XVcxOFJp3mkw"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('yolov5')\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms as T\n",
        "from models.yolo import Model, Detect\n",
        "import yaml\n",
        "from utils.loss import ComputeLoss\n",
        "from torchinfo import summary\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "OWd07IAW4ZJ9"
      },
      "outputs": [],
      "source": [
        "# Dataset de YOLO\n",
        "\n",
        "class YoloDataset(Dataset):\n",
        "    def __init__(self, root, img_size=640, augment=False):\n",
        "        self.image_dir = os.path.join(root, 'images')\n",
        "        self.label_dir = os.path.join(root, 'labels')\n",
        "        self.filenames = sorted(os.listdir(self.image_dir))[:2]\n",
        "        self.img_size = img_size\n",
        "\n",
        "        transforms =[\n",
        "              A.Resize(img_size, img_size),\n",
        "              A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),\n",
        "              A.ToTensorV2()\n",
        "              ]\n",
        "        if augment:\n",
        "            # Completar con rotaciones\n",
        "          pass\n",
        "\n",
        "        self.transform = A.Compose(transforms)\n",
        "        self.yaml_path = '/' + os.path.join(*root.split('/')[:-1], 'data.yaml')\n",
        "        with open(self.yaml_path, 'r') as f:\n",
        "            self.yaml = yaml.safe_load(f)\n",
        "        self.cls_to_idx = {cls: idx for idx, cls in enumerate(self.yaml['names'])}\n",
        "        self.idx_to_cls = {idx: cls for idx, cls in enumerate(self.yaml['names'])}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.filenames[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        label_path = os.path.join(self.label_dir, img_name.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
        "        img = np.array(Image.open(img_path).convert('RGB'))\n",
        "        labels = []\n",
        "        classes = []\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f:\n",
        "                    vals = list(map(float, line.strip().split()))\n",
        "                    if len(vals) >= 5:\n",
        "                        cls, bbox = int(vals[0]), vals[1:5]\n",
        "                        classes.append(cls)\n",
        "                        labels.append(bbox)\n",
        "        transformed = self.transform(image=img, bboxes=labels, class_labels=classes)\n",
        "        img = transformed['image']\n",
        "        boxes = torch.tensor(transformed['bboxes'], dtype=torch.float32)\n",
        "        classes = torch.tensor(transformed['class_labels'], dtype=torch.float32).unsqueeze(1)\n",
        "        if boxes.numel() > 0:\n",
        "            labels = torch.cat([classes, boxes], dim=1)\n",
        "        else:\n",
        "            labels = torch.zeros((0, 5), dtype=torch.float32)\n",
        "\n",
        "        return img, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "# Convierte datos a formato YOLO\n",
        "def collate_fn(batch):\n",
        "    imgs, targets = [], []\n",
        "    for i, (img, target) in enumerate(batch):\n",
        "        imgs.append(img)\n",
        "        target = torch.cat([torch.full((target.size(0), 1), i), target], dim=1)\n",
        "        targets.append(target)\n",
        "\n",
        "    imgs = torch.stack(imgs, dim=0)\n",
        "    targets = torch.cat(targets, dim=0)\n",
        "\n",
        "    return imgs, targets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-yafJLA_WA7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749b339f-109d-4020-e200-f8808d447288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ v7.0-416-gfe1d4d99 Python-3.11.12 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "from models.yolo import Model\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dataset = YoloDataset('/content/Vehicle-Detection-1/train')\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,           # antes era 128\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=0            # evita problemas paralelos en RAM/Colab\n",
        ")\n",
        "\n",
        "\n",
        "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", classes=len(train_dataset.yaml['names']), pretrained=True, autoshape=False).cpu()\n",
        "hyp_path = '/content/yolov5/data/hyps/hyp.scratch-low.yaml'\n",
        "\n",
        "with open(hyp_path) as f:\n",
        "    hyp = yaml.safe_load(f)\n",
        "\n",
        "# Congelar modelo\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Descongelar cabeza\n",
        "for param in model.model[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.hyp = hyp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DQwyDaPjVT2O"
      },
      "outputs": [],
      "source": [
        "from yolov5.utils.augmentations import Albumentations\n",
        "from yolov5.utils.loss import ComputeLoss\n",
        "\n",
        "def train(model, dataloader, optimizer, epochs, transforms):\n",
        "    \"\"\"\n",
        "    Finetunea la cabeza de detecciÃ³n de YOLOv5.\n",
        "    Usa Albumentations(transforms) y ComputeLoss (CIoU + BCE obj/cls).\n",
        "    Imprime el promedio de cada tÃ©rmino al final de cada epoch.\n",
        "    \"\"\"\n",
        "    model.model.transform = transforms\n",
        "    compute_loss = ComputeLoss(model)\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        tot_l, box_l, obj_l, cls_l = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "        for imgs, targets in dataloader:\n",
        "            imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "            preds = model(imgs)\n",
        "            loss, (l_box, l_obj, l_cls) = compute_loss(preds, targets)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tot_l  += loss.item()\n",
        "            box_l  += l_box.item()\n",
        "            obj_l  += l_obj.item()\n",
        "            cls_l  += l_cls.item()\n",
        "\n",
        "        n = len(dataloader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | total={tot_l/n:.4f} \"\n",
        "              f\"| box={box_l/n:.4f} | obj={obj_l/n:.4f} | cls={cls_l/n:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "from yolov5.utils.loss import ComputeLoss\n",
        "\n",
        "def eval(model, dataloader):\n",
        "    \"\"\"\n",
        "    Calcula los promedios de CIoU, BCEâ€‘class y BCEâ€‘object sin retroâ€‘propagaciÃ³n.\n",
        "    Imprime los resultados al final.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    compute_loss = ComputeLoss(model)\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    ciou_sum, bce_obj_sum, bce_cls_sum, n_batches = 0.0, 0.0, 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in dataloader:\n",
        "            imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "            preds = model(imgs)\n",
        "            _, (l_box, l_obj, l_cls) = compute_loss(preds, targets)\n",
        "\n",
        "            ciou_sum   += l_box.item()\n",
        "            bce_obj_sum += l_obj.item()\n",
        "            bce_cls_sum += l_cls.item()\n",
        "            n_batches  += 1\n",
        "\n",
        "    print(f\"Mean scores: CIoU {ciou_sum/n_batches:.4f}, \"\n",
        "          f\"BCE class: {bce_cls_sum/n_batches:.4f}, \"\n",
        "          f\"BCE object: {bce_obj_sum/n_batches:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(model, train_loader)   # o val_loader si lo tienes\n",
        "\n"
      ],
      "metadata": {
        "id": "_7TfAplOkti0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "532025fa-6ff3-4e81-b7cd-cf5effd55c84"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 3 is out of bounds for dimension 0 with size 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-564f425b03b7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# o val_loader si lo tienes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-910806fe30cc>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mciou_sum\u001b[0m   \u001b[0;34m+=\u001b[0m \u001b[0ml_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/yolov5/utils/loss.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, p, targets)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mlbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# box loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mlobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# object loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mtcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/yolov5/utils/loss.py\u001b[0m in \u001b[0;36mbuild_targets\u001b[0;34m(self, p, targets)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mgain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# xyxy gain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;31m# Match targets to anchors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F4xzinlYo_wx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}